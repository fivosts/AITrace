config {
  server_sampling: true
  prediction_type: "step"
  batch_size: 1
  temperature_micros: 1000000
  server_port: 8080
  termination_criteria {
    maxlen {
      maximum_tokens_in_sample: 512
    }
  }
}
