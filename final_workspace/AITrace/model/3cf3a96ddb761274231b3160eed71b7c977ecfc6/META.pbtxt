config {
  dataset {
    hecht_dataset {
      local_tar_archive: "$PWD/../datasets/Kuflik_Hecht/museum_data.zip"
    }
  }
  architecture {
    backend: TORCH_LSTM
    embedding_size: 128
    dropout_prob: 0.2
    hidden_size: 512
    num_hidden_layers: 2
    intermediate_size: 64
    output_size: 512
    layer_norm_eps: 1e-13
  }
  training {
    num_epochs: 650
    num_warmup_steps: 5000
    random_seed: 12345
    batch_size: 64
    adam_optimizer {
      initial_learning_rate_micros: 20
    }
    validation_percentage: 0.0
  }
}
