// The file defines the protos for describing AITrace instances.

syntax = "proto2";

package AITrace;

option go_package = "AITracepb";
option java_multiple_files = true;
option java_outer_classname = "ModelProto";
option java_package = "com.AITrace";

import "proto/dataset.proto";

// The specification of a AITrace model.
message Model {
  optional AITrace.Dataset      dataset          = 1;
  optional NetworkArchitecture  architecture     = 2;
  optional TrainingOptions      training         = 3;
}

// The specification of a AITrace language model.
message NetworkArchitecture {
  enum Backend {
    TORCH_LSTM = 0;
  }
  optional Backend backend         = 1;
  // The size of the input embedding layer. Only required if backend == KERAS_SEQ.
  // Must be > 0.
  optional int32 embedding_size    = 2;
  // dropout probability across all model components.
  optional float dropout_prob      = 4;
  //Size of the encoder layers and the pooler layer.
  optional int32 hidden_size       = 5;
  // The messages below correspong to BERT parameters.
  // Number of hidden layers in the Transformer encoder.
  optional int32 num_hidden_layers = 6;
  // The size of intermediate FC layer of both prediction heads.
  optional int32 intermediate_size = 7;
  // The size of last FC layer of both prediction heads.
  optional int32 output_size       = 8;
  // The dropout ratio for the attention probabilities.
  optional float layer_norm_eps    = 9;
}

// Options used for training a AITrace language model.
message TrainingOptions {
  // The number of epochs to train the network for.
  optional int32 num_epochs       = 1;
  // BERT only. Number of pre-training steps.
  optional int32 num_warmup_steps = 3;
  // Random seed for data generation.
  optional int32 random_seed      = 4;
  // The training batch size.
  optional int32 batch_size       = 5;
  // The optimizer configuration.
  oneof optimizer {
    AdamOptimizer adam_optimizer  = 6;
    RmsPropOptimizer rmsprop_optimizer = 7;
  }
  // Percentage of corpus used for validation.
  optional float validation_percentage = 8;
}

// The field name suffix '_micros' shows that the value contained in the field
// is converted at runtime to a floating point number by dividing it by 1e6.
// The reason for _micros fields is so that we can realiably encode and compare
// protos without having to worry about floating point rounding and comparisons.
message AdamOptimizer {
  // The initial learning rate. Must be >= 0. A recommended starting value is
  // 2000 (i.e. real value 0.002).
  optional int32 initial_learning_rate_micros = 1;
  // The ratio by which the learning rate decays per epoch of training. Must be
  // >= 0. A recommended starting value is 5000 (i.e. real value 0.05).
  optional int32 learning_rate_decay_per_epoch_micros = 2;
  // Must be in real value range 0 < beta_1 < 1. A recommended starting value
  // is 900000 (i.e. real value 0.9).
  optional int32 beta_1_micros = 3;
  // Must be in real value range 0 < beta_2 < 1. A recommended starting value
  // is 999000 (i.e. real value 0.999).
  optional int32 beta_2_micros = 4;
  // The normalized gradient clip value. A recommended starting value is 5000000
  // (ie. real value 5.0).
  optional int32 normalized_gradient_clip_micros = 5;
}

message RmsPropOptimizer {
  // The initial learning rate. Must be >= 0. A recommended starting value is
  // 1000 (i.e. real value 0.001).
  optional int32 initial_learning_rate_micros = 1;
  // The ratio by which the learning rate decays per epoch of training. Must be
  // >= 0. A recommended starting value is 0.
  optional int32 learning_rate_decay_per_epoch_micros = 2;
}

// A generated sample. Instances of this proto are returned by a Model's
// Sample() method.
message Sample {
  optional string original_input         = 1;
  optional string sample_feed            = 2;
  optional string text                   = 3;
  optional string encoded_text           = 4;
  optional int32  sample_time_ms         = 5;
  optional string sample_indices         = 6;
  optional string encoded_sample_indices = 7;
  optional string feature_vector         = 8;
  // Sampling may be batches, so that the sum of sample_time_ms over a range
  // of samples may be much higher than the actual amount of time required to
  // sample the set. This field contains the number of milliseconds between the
  // last sample completing and this sample completing, so that by summing
  // wall_time_ms, it is possible to get an accurate idea of the actual time
  // taken to produce a set of samples.
  optional int32 wall_time_ms              = 9;
  optional int64 sample_start_epoch_ms_utc = 10;
  optional int32 num_tokens                = 11;
  optional bool  compile_status            = 12;
  optional bool  categorical_sampling      = 13;
  optional int32 train_step                = 14;
  optional string date_added               = 15;
}
